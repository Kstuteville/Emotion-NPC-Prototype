# Emotion-Responsive NPC Villager Prototype

A 7-week UX research project exploring how real-time player emotion affects interactions with a game character.

We are building a small NPC prototype that:
‚Ä¢ Detects player facial emotions (happy, neutral, angry)
‚Ä¢ Reacts with animation + lighting changes in Unreal Engine
‚Ä¢ Responds with voice using mood-aware AI dialogue
‚Ä¢ Shows playful personality and boundaries like a real villager

## üéØ Research Question
How does real-time emotional responsiveness change player perception of NPC presence, empathy, and "aliveness"?

## üß© Technology Stack
**Week 1‚Äì2:**  
Python + MediaPipe + OpenCV for FER (local/offline)  

**Week 3‚Äì7:**  
Unreal Engine 5 for animation + lighting + integration  
Speech-to-text + small LLM model for dialogue  
Azure Speech or equivalent for voice output  

## ‚úÖ Final Deliverable (Week 7)
‚Ä¢ Interactive installation
‚Ä¢ Webcam + microphone NPC interaction  
‚Ä¢ Emotion-driven behavior and conversation  
‚Ä¢ Playtest results + UX findings  
‚Ä¢ Documentation, presentation, and demo video

## üó∫Ô∏è Timeline
| Week | Focus |
|------|------|
| 1 | Real-time facial emotion detection (Python) |
| 2 | Emotional behavior design + smoothing |
| 3 | UE5 integration: animation + lighting |
| 4 | Voice input + basic replies |
| 5 | Emotion-aware AI dialogue |
| 6 | Playtesting + insights |
| 7 | Polish + final demo + presentation |

## üìÇ Repo Structure
